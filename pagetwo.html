<html>
    <head>
        <body>
            <h1 style="color: rgb(48, 118, 175);">challenges</h1>
            <li><a href="pageone.html">Definition</a></li>
            <li><a href="pagetwo.html">challenges</a></li>
            <li><a href="pagethree.html">Applications</a></li>
            <li><a href="pagefour.html">Impact</a></li>
            <img src="boardbookit-artificial-intelligence-in-corporate-governance-image-01.jpg" alt="artificial intelligence" width="500" height="250">
            <p>The cognitive capabilities of current architectures are very limited, using only a simplified version of what intelligence is really capable of. For instance, the human mind has come up with ways to reason beyond measure and logical explanations to different occurrences in life. What would have been otherwise straightforward, an equivalently difficult problem may be challenging to solve computationally as opposed to using the human mind. This gives rise to two classes of models: structuralist and functionalist. The structural models aim to loosely mimic the basic intelligence operations of the mind such as reasoning and logic. The functional model refers to the correlating data to its computed counterpart.

                The overall research goal of artificial intelligence is to create technology that allows computers and machines to function in an intelligent manner. The general problem of simulating (or creating) intelligence has been broken down into sub-problems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention.</p>
                
                    <p><b>Planning</b></p>
                    <p>Intelligent agents must be able to set goals and achieve them. They need a way to visualize the future—a representation of the state of the world and be able to make predictions about how their actions will change it—and be able to make choices that maximize the utility (or "value") of available choices.

                        In classical planning problems, the agent can assume that it is the only system acting in the world, allowing the agent to be certain of the consequences of its actions. However, if the agent is not the only actor, then it requires that the agent can reason under uncertainty. This calls for an agent that can not only assess its environment and make predictions but also evaluate its predictions and adapt based on its assessment.
                        
                        Multi-agent planning uses the cooperation and competition of many agents to achieve a given goal. Emergent behavior such as this is used by evolutionary algorithms and swarm intelligence.</p>
                        <p><b>Learning</b></p> 
                        <p>Machine learning (ML), a fundamental concept of AI research since the field's inception, is the study of computer algorithms that improve automatically through experience.

                            Unsupervised learning is the ability to find patterns in a stream of input, without requiring a human to label the inputs first. Supervised learning includes both classification and numerical regression, which requires a human to label the input data first. Classification is used to determine what category something belongs in, and occurs after a program sees a number of examples of things from several categories. Regression is the attempt to produce a function that describes the relationship between inputs and outputs and predicts how the outputs should change as the inputs change. Both classifiers and regression learners can be viewed as "function approximators" trying to learn an unknown (possibly implicit) function; for example, a spam classifier can be viewed as learning a function that maps from the text of an email to one of two categories, "spam" or "not spam". Computational learning theory can assess learners by computational complexity, by sample complexity (how much data is required), or by other notions of optimization. In reinforcement learning the agent is rewarded for good responses and punished for bad ones. The agent uses this sequence of rewards and punishments to form a strategy for operating in its problem space.</p>
                            <style>
                                body{
                                    background-image: url(https://elearningindustry.com/wp-content/uploads/2019/06/embrace-artificial-intelligence-in-the-workplace.jpg);
                                    background-size: cover;
                                    color: rgb(192, 69, 11);
                                    font-style: oblique;
                                    font-size: larger;
                                }
                            </style>
            
           
        </body>
    </head>
</html>